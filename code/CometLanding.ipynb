{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation in Python (CS2006 P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the 12th of November 2014, the European Space Agency lander Philae made the first ever soft landing of a spacecraft on the surface of a comet, 67P/Churyumov-Gerasimenko, having been carried there by the probe Rosetta. The news of the acheivement was disseminated through various social media platforms over the following days and weeks, including Twitter. This notebook analyses data independently gathered from Twitter to track the volume and nature of user activity related to the landing over the period of 3 weeks after the landing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from plotly import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import operator\n",
    "from collections import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8b6cff47a56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/ir47/IdeaProjects/Second Year/CS2006/Python2/code/wordcloud.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquery_integral_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_integral_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munigrams_and_bigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/CometLanding.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77319"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['id_str'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTweets = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data contained some duplicate tweets, which were removed, and the number of total remaining unique tweets is displayed below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets: 77268\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Tweets: \" + str(numTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users is displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['from_user'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tweets by language are displayed here. By far the most common is US English, with 52316 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = df.groupby('user_lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_lang\n",
       "ar           428\n",
       "bg             1\n",
       "ca           309\n",
       "cs            42\n",
       "da            89\n",
       "de          2916\n",
       "el            29\n",
       "en         52316\n",
       "en-AU          1\n",
       "en-GB         23\n",
       "en-gb       1972\n",
       "es          7540\n",
       "es-MX          2\n",
       "eu            62\n",
       "fa             2\n",
       "fi           108\n",
       "fil           10\n",
       "fr          3313\n",
       "gl            36\n",
       "he             2\n",
       "hi             2\n",
       "hu            41\n",
       "id            66\n",
       "it          2664\n",
       "ja          1514\n",
       "ko            98\n",
       "msa            1\n",
       "nb             1\n",
       "nl           838\n",
       "no            36\n",
       "pl           157\n",
       "pt           508\n",
       "pt-PT          1\n",
       "ro             8\n",
       "ru           794\n",
       "sv           126\n",
       "th            57\n",
       "tr           761\n",
       "uk            43\n",
       "ur             1\n",
       "vi             1\n",
       "xx-lc         24\n",
       "zh-CN          6\n",
       "zh-Hans        6\n",
       "zh-cn        285\n",
       "zh-tw         27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 52316), ('es', 7540), ('fr', 3313), ('de', 2916), ('it', 2664), ('en-gb', 1972), ('ja', 1514), ('nl', 838), ('ru', 794), ('tr', 761), ('pt', 508), ('ar', 428), ('ca', 309), ('zh-cn', 285), ('pl', 157), ('sv', 126), ('fi', 108), ('ko', 98), ('da', 89), ('id', 66), ('eu', 62), ('th', 57), ('uk', 43), ('cs', 42), ('hu', 41), ('no', 36), ('gl', 36), ('el', 29), ('zh-tw', 27), ('xx-lc', 24), ('en-GB', 23), ('fil', 10), ('ro', 8), ('zh-Hans', 6), ('zh-CN', 6), ('es-MX', 2), ('he', 2), ('fa', 2), ('hi', 2), ('en-AU', 1), ('pt-PT', 1), ('bg', 1), ('nb', 1), ('vi', 1), ('msa', 1), ('ur', 1)]\n"
     ]
    }
   ],
   "source": [
    "languages = []\n",
    "\n",
    "\n",
    "for index, row in dfReplies.iterrows():\n",
    "        text = (row['user_lang'])\n",
    "        languages.append(text)\n",
    "\n",
    "        \n",
    "languageCount = {}\n",
    "\n",
    "for lang in languages:\n",
    "    if lang not in languageCount:\n",
    "        languageCount[lang] = 1\n",
    "    else:\n",
    "        counter = languageCount.get(lang,'none')\n",
    "        languageCount.update({lang: counter+1})\n",
    "        \n",
    "\n",
    "topLangs = sorted(languageCount.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the top 4 languages\n",
    "topLanguage = topLangs[0][0]\n",
    "topLanguageNum = topLangs[0][1]\n",
    "    \n",
    "secondLanguage = topLangs[1][0]\n",
    "secondLanguageNum = topLangs[1][1]\n",
    "    \n",
    "thirdLanguage = topLangs[2][0]\n",
    "thirdLanguageNum = topLangs[2][1]\n",
    "\n",
    "fourthLanguage = topLangs[3][0]\n",
    "fourthLanguageNum = topLangs[3][1]\n",
    "\n",
    "totalLanguage = sum(languageCount.values())\n",
    "otherLanguageNum = (totalLanguage-(topLanguageNum+secondLanguageNum+thirdLanguageNum+fourthLanguageNum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ir47/20.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = {\n",
    "    'data': [{'labels': [topLanguage,secondLanguage,thirdLanguage,fourthLanguage,\" \\\"Other\\'\"],\n",
    "              'values': [topLanguageNum,secondLanguageNum,thirdLanguageNum,fourthLanguageNum,otherLanguageNum],\n",
    "              'type': 'pie'}],\n",
    "    'layout': {'title': 'Language share'}\n",
    "     }\n",
    "\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pie chart shows the share each of language has on the tweets in the dataset. The chart clearly shows that english was the most used language taking over 2/3 of the set with 67.7% of the tweets in the set being written in english. This would be as expected as the comet launch was a eurpoean launch and english is the most spoken language in europe. This then shows that english would be the most used language as the majority of people who would be tweeting about the comet landing. Having english as the most used language would also be expected due to people from the US tweeting about the landing. users in america would be thought to be tweeting about the event due to many americans having an interest in space landings and probes, this would then increase the number of tweets being sent in english. \n",
    "\n",
    "The next three popular languages are Spanish, French and German, this would also be expected to be the case due to the landing mission being european. This means that people in those countrys having a specific interest in the landing due to their country having something to do with the landing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of tweets were actually retweets, which meant that they started with the letters \"RT\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoRT = df[~df.text.str.startswith('RT', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numReTweets = numTweets - len(dfNoRT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of retweets: 59999\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of retweets: \" + str(numReTweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly 1/2 of the remainder are replies to earlier tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723\n"
     ]
    }
   ],
   "source": [
    "dfReplies = df\n",
    "numReplies = 0\n",
    "\n",
    "\n",
    "for index, row in dfReplies.iterrows():\n",
    "        text = (row['in_reply_to_screen_name'])\n",
    "        if(not pd.isnull(text)):\n",
    "            numReplies +=1\n",
    "\n",
    "            \n",
    "print(numReplies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of replies: 1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of replies: \" + str(numReplies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtags are an important "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hashtags = []\n",
    "for index, row in dfNoRT.iterrows():\n",
    "    text = (row['text'].split(\" \"))       \n",
    "    for token in text:\n",
    "        re.sub('[\\W_]', '', token)\n",
    "        if token.startswith('#'):\n",
    "            hashtags.append(str(token))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'#cometlanding'=>1834\n",
      "'#CometLanding'=>12741\n",
      "'#ESA'=>194\n",
      "'#Rosetta'=>1471\n",
      "'#Philae'=>734\n",
      "'#CometLanding:'=>161\n",
      "'#rosettamission'=>169\n",
      "'#Cometlanding'=>165\n",
      "'#67P'=>400\n",
      "'#CometLanding.'=>244\n",
      "'#rosetta'=>178\n",
      "'#WishKoSaPasko'=>929\n",
      "'#HappyBirthdaySandaraPark'=>928\n"
     ]
    }
   ],
   "source": [
    "hashtagCount = {}\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    if hashtag not in hashtagCount:\n",
    "        hashtagCount[hashtag] = 1\n",
    "    else:\n",
    "        counter = hashtagCount.get(hashtag,'none')\n",
    "        hashtagCount.update({hashtag: counter+1})\n",
    "        \n",
    "for key,val in hashtagCount.items():\n",
    "    if val>150:\n",
    "        print (repr(key) + \"=>\" + repr(val))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOPWORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e67421848b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CometLanding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOPWORDS' is not defined"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for key,val in hashtagCount.items():\n",
    "    words.append(key)\n",
    "    \n",
    "words = [e[1:] for e in words]\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"CometLanding\")\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(background_color='white',stopwords=stopwords,max_words=30000,max_font_size=40, random_state=42).generate(str(hashtags))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ir47/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [go.Bar(x=['Tweets', 'Retweets', 'Replies'],y=[numTweets,numReTweets,numReplies])]\n",
    "layout = go.Layout(\n",
    "    title='Number of Retweets, Replies and Tweets',\n",
    "    yaxis=dict(\n",
    "        title='Usage',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows the total number of unique Tweets that were in the data set. The graph then highlights how many of those tweets are Retweets and how many are replies to other tweets. As can be clearly seen from the graph the majority of the dataset is made up of Retweets with over 59 thousand Retweets being present. The set also includes a number of replies to tweets, however, when the amount of replies is compared to the number of Retweets it shows how many more Retweets there are over replies. This is shown with there only being 1723 replies in the set compared with the over 59 thousand Retweets. \n",
    "\n",
    "One of the main reaons for this mass difference in the number of Retweets to replies is the nature of what each of them actually do. Retweeting a tweet is more designed to share that perticular tweet with your followers as it may be something interesting or something you agree with. Whereas a reply is used for the more conversational aspect of twitter it is there to add a response or to add more information to a tweet and in some cases it can be used as a convorsation tool between people. \n",
    "\n",
    "Another possible reason for Retweets taking up a larger amount of the dataset over replies is that they are mush easier to utilise than replies. When a user goes to Retweet a tweet then they can simply just click Retweet which will then share this tweet with their followers. Whereas with a reply more thought must be put into the process as the actual content of the reply must be thought of and written out. This may be one of the reasons for Retweets being more prominent as simply they are quicker and easier to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSource = df\n",
    "import re\n",
    "items = []\n",
    "for index, row in dfSource.iterrows():\n",
    "    text = (row['source'])\n",
    "    for token in str(text):\n",
    "        if token.endswith('>'):\n",
    "            split1 = text.split(\"</a>\")\n",
    "            split2 = str(split1).split(\">\")\n",
    "            split2 = str(split2).split(\",\")\n",
    "            items.append(str(split2[1]))\n",
    "            \n",
    "appCount = {}\n",
    "\n",
    "for device in items:\n",
    "    if device not in appCount:\n",
    "        appCount[device] = 1\n",
    "    else:\n",
    "        counter = appCount.get(device,'none')\n",
    "        appCount.update({device: counter+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topItems = sorted(appCount.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the top 4 applications\n",
    "topApplication = topItems[0][0]\n",
    "topApplicationNum = topItems[0][1]\n",
    "    \n",
    "secondApplication = topItems[1][0]\n",
    "secondApplicationNum = topItems[1][1]\n",
    "    \n",
    "thirdApplication = topItems[2][0]\n",
    "thirdApplicationNum = topItems[2][1]\n",
    "\n",
    "fourthApplication = topItems[3][0]\n",
    "fourthApplicationNum = topItems[3][1]\n",
    "\n",
    "totalApplications = sum(appCount.values())\n",
    "otherApplicationNum = (totalApplications-(topApplicationNum+secondApplicationNum+thirdApplicationNum+fourthApplicationNum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ir47/18.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = {\n",
    "    'data': [{'labels': [topApplication,secondApplication,thirdApplication,fourthApplication,\" \\\"Other\\'\"],\n",
    "              'values': [topApplicationNum,secondApplicationNum,thirdApplicationNum,fourthApplicationNum,otherApplicationNum],\n",
    "              'type': 'pie'}],\n",
    "    'layout': {'title': 'Application share of tweets'}\n",
    "     }\n",
    "\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows the top 4 applicaions which were used to used to send tweets in the dataset. The chart also shows what percentage of other applications were used to send tweets. As can be seen from the chart above the majority of tweets were sent from the \"Twitter Web Client\" as that was used to send 36.1% of tweets used in the set. The next two most popular applications used were mobile applications as \"Twitter for iPhone\" has 17.8% of the tweets and \"Twitter for Android\" having 16.5%. These figures show an interesting point as although the web application had overall more than all of the other applications, if you were to combine the two mobiles applications it would come out at 34.3% just under the 36.1% of the web application. \n",
    "\n",
    "This shows that mobile applcations were infact very close to being the most used application for sending tweets in the set. It could also be agruged that mobile applications could have sent the most tweets as other mobile applications such as \"Tweetbot for iOS\" would be stored in the other section of the chart meaning that all considered it is no longer the case that traditional means such as web applications on computers will be the most used applications when it comes to social media. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77267"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSource = df\n",
    "import re\n",
    "dates = []\n",
    "for index, row in dfSource.iterrows():\n",
    "    text = (row['created_at'])\n",
    "    dates.append(text[0:10])\n",
    "        \n",
    "len(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateCount = {}\n",
    "counter =0\n",
    "\n",
    "for date in dates:\n",
    "    if date not in dateCount:\n",
    "        dateCount[date] = 1\n",
    "    else:\n",
    "        counter = dateCount.get(date,'none')\n",
    "        dateCount.update({date: counter+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Fri Dec 05 Number of Tweets: 87\n",
      "Date: Thu Dec 04 Number of Tweets: 200\n",
      "Date: Wed Dec 03 Number of Tweets: 311\n",
      "Date: Tue Dec 02 Number of Tweets: 475\n",
      "Date: Mon Dec 01 Number of Tweets: 603\n",
      "Date: Sun Nov 30 Number of Tweets: 343\n",
      "Date: Sat Nov 29 Number of Tweets: 428\n",
      "Date: Fri Nov 28 Number of Tweets: 711\n",
      "Date: Thu Nov 27 Number of Tweets: 497\n",
      "Date: Wed Nov 26 Number of Tweets: 400\n",
      "Date: Wed Nov 12 Number of Tweets: 73212\n"
     ]
    }
   ],
   "source": [
    "values =[]\n",
    "dateKeys = []\n",
    "\n",
    "for key,val in dateCount.items():\n",
    "    values.append(val)\n",
    "    dateKeys.append(str(key))\n",
    "    print(\"Date: \"+ str(key) + \" Number of Tweets: \" + str(val))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ir47/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [go.Bar(x=dateKeys,y=values)]\n",
    "layout = go.Layout(\n",
    "    title='Number of Tweets per day',\n",
    "    yaxis=dict(\n",
    "        title='Tweets',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows the number of tweets which were sent on each day in the dataset. As can be seen from the graph the dataset contained a majority of tweets sent on 12th November, with 73 thousand tweets in the set being sent on that day. This would be some what expected as on that day was the lander reached its comet destination. As this was a day which had been greatly anticipated for nearly a decade it would be expected for the dataset to reflect this with the number of tweets. \n",
    "\n",
    "The graph also shows us that on 1st December there was a slight increase in the number of tweets over previous days about the Comet landing. One of the resons for this could be that on that day some of the first images from the comet were released which may have then caused people to begining tweeting about the pictures. However this increase is only a fraction to the amount of tweets which were sent on the actual comet landing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
